{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28436abb9e9547ab9a2136dc24fd55a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26591540b1544c829e39227640c33f71",
              "IPY_MODEL_7ecbaea1b03e409ea159f8f5ccd52013",
              "IPY_MODEL_d3e62e80525b405ca40569db9c9268be"
            ],
            "layout": "IPY_MODEL_23e328b3f665488b9064fd359d32bb10"
          }
        },
        "26591540b1544c829e39227640c33f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425e8bda926945ed8e896a67560e2a08",
            "placeholder": "​",
            "style": "IPY_MODEL_80d7bac8dd2240fb8baea173f71200d4",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "7ecbaea1b03e409ea159f8f5ccd52013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c384f55a8a14b6e954606683529f6a0",
            "max": 381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474cd1311916482abfed1f54f5155b2e",
            "value": 381
          }
        },
        "d3e62e80525b405ca40569db9c9268be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6299f2081d2f460ab15ea9d16b908d44",
            "placeholder": "​",
            "style": "IPY_MODEL_98e4528b076041ecbb0044aaa24ebe1d",
            "value": " 381/381 [00:00&lt;00:00, 6.41kB/s]"
          }
        },
        "23e328b3f665488b9064fd359d32bb10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425e8bda926945ed8e896a67560e2a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d7bac8dd2240fb8baea173f71200d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c384f55a8a14b6e954606683529f6a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474cd1311916482abfed1f54f5155b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6299f2081d2f460ab15ea9d16b908d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e4528b076041ecbb0044aaa24ebe1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bde118774e147a083c50d73ab9de2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4c62b7cf2354d5cb48454cd52c9fb06",
              "IPY_MODEL_275137060e334bcc801c5b8e481fca1d",
              "IPY_MODEL_a4e5f3e087ed429a89153a5e79f93bbc"
            ],
            "layout": "IPY_MODEL_74ef7bc8f13e46db9632a4aefd4328f4"
          }
        },
        "d4c62b7cf2354d5cb48454cd52c9fb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00d15f9eb1d4be7ab308c5e019cbc26",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc6bc0dddff4a73b2fab0737240e7fa",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "275137060e334bcc801c5b8e481fca1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c187d7c886a7448da534bc154acd2bf2",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15984424fa8a4823b580c79cf70be6a0",
            "value": 384
          }
        },
        "a4e5f3e087ed429a89153a5e79f93bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3cbbc29bc14af894c9c9394ec34330",
            "placeholder": "​",
            "style": "IPY_MODEL_580982d524d7453399c4b16b3f6a0517",
            "value": " 384/384 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "74ef7bc8f13e46db9632a4aefd4328f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00d15f9eb1d4be7ab308c5e019cbc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc6bc0dddff4a73b2fab0737240e7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c187d7c886a7448da534bc154acd2bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15984424fa8a4823b580c79cf70be6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f3cbbc29bc14af894c9c9394ec34330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580982d524d7453399c4b16b3f6a0517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "463ab96b001a4c5997b9412daec3d3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f02c7757241b495697077659592b1823",
              "IPY_MODEL_86a4a1dcaee84af880c1612eabd1e6c5",
              "IPY_MODEL_0b7218963dd445879654af1eea8068b1"
            ],
            "layout": "IPY_MODEL_02a005fa1f8c44f7bd61d0e901fdc702"
          }
        },
        "f02c7757241b495697077659592b1823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c564d7d79ce4bc592174f2e80f3a475",
            "placeholder": "​",
            "style": "IPY_MODEL_f8b00357500248e2b7c17e81dd87e4a5",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "86a4a1dcaee84af880c1612eabd1e6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ac1508cd3147c9b97784080cec8f95",
            "max": 824793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c70cb49f5846fdbef1945a64051723",
            "value": 824793
          }
        },
        "0b7218963dd445879654af1eea8068b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f5770fefa843bda7cd1cceb97b37e6",
            "placeholder": "​",
            "style": "IPY_MODEL_5e7b9ac8adf34c8c95a5df51becb50ee",
            "value": " 825k/825k [00:00&lt;00:00, 978kB/s]"
          }
        },
        "02a005fa1f8c44f7bd61d0e901fdc702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c564d7d79ce4bc592174f2e80f3a475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b00357500248e2b7c17e81dd87e4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ac1508cd3147c9b97784080cec8f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c70cb49f5846fdbef1945a64051723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1f5770fefa843bda7cd1cceb97b37e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e7b9ac8adf34c8c95a5df51becb50ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67840613e06c45589b6c59db49e2a75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c26d5afd73942278a20ae9f720aeba0",
              "IPY_MODEL_0de2c11dc56f43e2b602ed5bc6043ab9",
              "IPY_MODEL_70e9f788465b4670a57851ad05f0e032"
            ],
            "layout": "IPY_MODEL_c460c2ecabc641f083d8814fc712b5d7"
          }
        },
        "6c26d5afd73942278a20ae9f720aeba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ebf6a0b0444b74853a5728ce64207d",
            "placeholder": "​",
            "style": "IPY_MODEL_30799ccd90f94b1eae884f90b9428620",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "0de2c11dc56f43e2b602ed5bc6043ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba660c8b4e9f4944b2f86671450c3155",
            "max": 2642362,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_492f7b521c594a2cbb9635f9ba54f3a6",
            "value": 2642362
          }
        },
        "70e9f788465b4670a57851ad05f0e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0837822d38564c6fad7ac895cf965249",
            "placeholder": "​",
            "style": "IPY_MODEL_735f596681b243058ddb368901d6f468",
            "value": " 2.64M/2.64M [00:01&lt;00:00, 2.11MB/s]"
          }
        },
        "c460c2ecabc641f083d8814fc712b5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ebf6a0b0444b74853a5728ce64207d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30799ccd90f94b1eae884f90b9428620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba660c8b4e9f4944b2f86671450c3155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492f7b521c594a2cbb9635f9ba54f3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0837822d38564c6fad7ac895cf965249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735f596681b243058ddb368901d6f468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a35de2f72622447ba7dc42d5036148a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1604ae420e9c40b8a87cca3615c484a1",
              "IPY_MODEL_bd4909b0622040699937e9808cff241f",
              "IPY_MODEL_57b68b1a7c9144779e849929585cbed5"
            ],
            "layout": "IPY_MODEL_1fcc842e6a29486799c3acdb8fecce25"
          }
        },
        "1604ae420e9c40b8a87cca3615c484a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1474271f9b4b5dbb36397346d4a4e0",
            "placeholder": "​",
            "style": "IPY_MODEL_286343fc925b497abd8d41be7958a275",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "bd4909b0622040699937e9808cff241f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70dbe6849ea24d879dd7ae9ce00d98cb",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06e0465b6d84447a8ddbeb4d100bf2bd",
            "value": 112
          }
        },
        "57b68b1a7c9144779e849929585cbed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac1be8239c34ca282cc8b545b5f9a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_bc54c1e02fd547f89398b6b91a1cb651",
            "value": " 112/112 [00:00&lt;00:00, 4.99kB/s]"
          }
        },
        "1fcc842e6a29486799c3acdb8fecce25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1474271f9b4b5dbb36397346d4a4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286343fc925b497abd8d41be7958a275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70dbe6849ea24d879dd7ae9ce00d98cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e0465b6d84447a8ddbeb4d100bf2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fac1be8239c34ca282cc8b545b5f9a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc54c1e02fd547f89398b6b91a1cb651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20db31860911405aa01889c98e25608b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504f1e17b0884059953899572e3b65c5",
              "IPY_MODEL_014522b9fcbc4dc99addc3b458c4995a",
              "IPY_MODEL_9661086622b24de484c75228bc4dc731"
            ],
            "layout": "IPY_MODEL_1c6f71111a3442c8b1b3855c46f5ad4b"
          }
        },
        "504f1e17b0884059953899572e3b65c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca16549663e4d6f9656cd8a2c9c2703",
            "placeholder": "​",
            "style": "IPY_MODEL_bf90f2b7a28e4b99bdd8533a6edf9f8e",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "014522b9fcbc4dc99addc3b458c4995a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e7f926ed4146ac808f20a83db25a79",
            "max": 543490667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad939f5ac4b348cdb0f34add3268ec39",
            "value": 543490667
          }
        },
        "9661086622b24de484c75228bc4dc731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d74b7ac391433381e0f8df060bb482",
            "placeholder": "​",
            "style": "IPY_MODEL_09a1b611f4cb4f4397eb5c11a0a2337a",
            "value": " 543M/543M [00:02&lt;00:00, 299MB/s]"
          }
        },
        "1c6f71111a3442c8b1b3855c46f5ad4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca16549663e4d6f9656cd8a2c9c2703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf90f2b7a28e4b99bdd8533a6edf9f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52e7f926ed4146ac808f20a83db25a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad939f5ac4b348cdb0f34add3268ec39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56d74b7ac391433381e0f8df060bb482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a1b611f4cb4f4397eb5c11a0a2337a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ghfaidi/Agile/blob/main/AspectPolarityByTarget_Preporc_Arabert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGwFYvTOOYvv",
        "outputId": "540a54d4-28c8-401d-a11a-3f6b03e47f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "zRVmX4-fTbMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f94b75-1686-465b-bf79-7bff7555403d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.functional import auroc, accuracy\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "6QJtEFjAtpBp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LR5N-L-Sov5T"
      },
      "outputs": [],
      "source": [
        "class HotelReviewTagger(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
        "    super().__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "    self.n_training_steps = n_training_steps\n",
        "    self.n_warmup_steps = n_warmup_steps\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "    output = self.classifier(output.pooler_output)\n",
        "    output = self.dropout(output)\n",
        "    output = torch.sigmoid(output)    \n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    \n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      for out_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(out_labels)\n",
        "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(out_predictions)\n",
        "\n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "    for i, name in enumerate(LABEL_COLUMNS):\n",
        "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
        "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    optimizer = AdamW(self.parameters(), lr=2e-5 , weight_decay=0.001)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer,\n",
        "      num_warmup_steps=self.n_warmup_steps,\n",
        "      num_training_steps=self.n_training_steps\n",
        "    )\n",
        "\n",
        "    return dict(\n",
        "      optimizer=optimizer,\n",
        "      lr_scheduler=dict(\n",
        "        scheduler=scheduler,\n",
        "        interval='step'\n",
        "      )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/SemEval2016_arabic/SemEval2016_arabic/new_dataset.xlsx')\n",
        "LABEL_COLUMNS = df.columns.tolist()[1:]"
      ],
      "metadata": {
        "id": "jwh0Tr1utzYk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(LABEL_COLUMNS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1AGf5JQONCe",
        "outputId": "f1608584-ee47-48ed-d685-de219151898b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "NT-hvaJ3uCrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ac2a23-5f25-4cfb-8d46-4556a623f328"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "BERT_MODEL_NAME = \"aubmindlab/bert-base-arabertv02\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ],
      "metadata": {
        "id": "s1lRzbFOuKtZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "28436abb9e9547ab9a2136dc24fd55a3",
            "26591540b1544c829e39227640c33f71",
            "7ecbaea1b03e409ea159f8f5ccd52013",
            "d3e62e80525b405ca40569db9c9268be",
            "23e328b3f665488b9064fd359d32bb10",
            "425e8bda926945ed8e896a67560e2a08",
            "80d7bac8dd2240fb8baea173f71200d4",
            "5c384f55a8a14b6e954606683529f6a0",
            "474cd1311916482abfed1f54f5155b2e",
            "6299f2081d2f460ab15ea9d16b908d44",
            "98e4528b076041ecbb0044aaa24ebe1d",
            "2bde118774e147a083c50d73ab9de2fb",
            "d4c62b7cf2354d5cb48454cd52c9fb06",
            "275137060e334bcc801c5b8e481fca1d",
            "a4e5f3e087ed429a89153a5e79f93bbc",
            "74ef7bc8f13e46db9632a4aefd4328f4",
            "b00d15f9eb1d4be7ab308c5e019cbc26",
            "4dc6bc0dddff4a73b2fab0737240e7fa",
            "c187d7c886a7448da534bc154acd2bf2",
            "15984424fa8a4823b580c79cf70be6a0",
            "1f3cbbc29bc14af894c9c9394ec34330",
            "580982d524d7453399c4b16b3f6a0517",
            "463ab96b001a4c5997b9412daec3d3db",
            "f02c7757241b495697077659592b1823",
            "86a4a1dcaee84af880c1612eabd1e6c5",
            "0b7218963dd445879654af1eea8068b1",
            "02a005fa1f8c44f7bd61d0e901fdc702",
            "3c564d7d79ce4bc592174f2e80f3a475",
            "f8b00357500248e2b7c17e81dd87e4a5",
            "a1ac1508cd3147c9b97784080cec8f95",
            "62c70cb49f5846fdbef1945a64051723",
            "d1f5770fefa843bda7cd1cceb97b37e6",
            "5e7b9ac8adf34c8c95a5df51becb50ee",
            "67840613e06c45589b6c59db49e2a75a",
            "6c26d5afd73942278a20ae9f720aeba0",
            "0de2c11dc56f43e2b602ed5bc6043ab9",
            "70e9f788465b4670a57851ad05f0e032",
            "c460c2ecabc641f083d8814fc712b5d7",
            "75ebf6a0b0444b74853a5728ce64207d",
            "30799ccd90f94b1eae884f90b9428620",
            "ba660c8b4e9f4944b2f86671450c3155",
            "492f7b521c594a2cbb9635f9ba54f3a6",
            "0837822d38564c6fad7ac895cf965249",
            "735f596681b243058ddb368901d6f468",
            "a35de2f72622447ba7dc42d5036148a6",
            "1604ae420e9c40b8a87cca3615c484a1",
            "bd4909b0622040699937e9808cff241f",
            "57b68b1a7c9144779e849929585cbed5",
            "1fcc842e6a29486799c3acdb8fecce25",
            "3e1474271f9b4b5dbb36397346d4a4e0",
            "286343fc925b497abd8d41be7958a275",
            "70dbe6849ea24d879dd7ae9ce00d98cb",
            "06e0465b6d84447a8ddbeb4d100bf2bd",
            "fac1be8239c34ca282cc8b545b5f9a7d",
            "bc54c1e02fd547f89398b6b91a1cb651"
          ]
        },
        "outputId": "664d52b9-7f47-4414-8444-d84f03880552"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/381 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28436abb9e9547ab9a2136dc24fd55a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bde118774e147a083c50d73ab9de2fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/825k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "463ab96b001a4c5997b9412daec3d3db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.64M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67840613e06c45589b6c59db49e2a75a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a35de2f72622447ba7dc42d5036148a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "20db31860911405aa01889c98e25608b",
            "504f1e17b0884059953899572e3b65c5",
            "014522b9fcbc4dc99addc3b458c4995a",
            "9661086622b24de484c75228bc4dc731",
            "1c6f71111a3442c8b1b3855c46f5ad4b",
            "3ca16549663e4d6f9656cd8a2c9c2703",
            "bf90f2b7a28e4b99bdd8533a6edf9f8e",
            "52e7f926ed4146ac808f20a83db25a79",
            "ad939f5ac4b348cdb0f34add3268ec39",
            "56d74b7ac391433381e0f8df060bb482",
            "09a1b611f4cb4f4397eb5c11a0a2337a"
          ]
        },
        "id": "89ZwPN7PuCJ6",
        "outputId": "8ed2c57b-c65f-4e5b-ee00-6fe29425a331"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20db31860911405aa01889c98e25608b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_sentiment(x):\n",
        "  if x == 'positive':\n",
        "    return 2\n",
        "  if x == 'negative':\n",
        "    return 0\n",
        "  if x == 'neutral':\n",
        "    return 1"
      ],
      "metadata": {
        "id": "DnUYmRJ5CehR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aspect_df = pd.read_excel('/content/drive/MyDrive/SemEval2016_arabic/SemEval2016_arabic/newfinal_dataset.xlsx')\n",
        "aspect_df = aspect_df.drop(['rid', 'id', 'from', 'to'], axis=1)\n",
        "aspect_df = aspect_df.fillna(method='ffill')"
      ],
      "metadata": {
        "id": "oONiMYJzvQlJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "G9NjTrRU0gwe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aspect_df[\"polarity\"].count('positive')\n",
        "collections.Counter(aspect_df['polarity'])"
      ],
      "metadata": {
        "id": "Yu7pesPKUMsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3af6ef3-4e28-4d36-e2a6-5f0f39b8260c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'positive': 6201, 'negative': 3636, 'neutral': 2733})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aspect_df['sentiment'] = aspect_df.polarity.apply(to_sentiment)\n",
        "aspect_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "xpiaLWVjFvsK",
        "outputId": "fb8a6e81-d055-4543-9184-672a63832f54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  OutOfScope  \\\n",
              "0               0         NaN   \n",
              "1               1         NaN   \n",
              "2               2         NaN   \n",
              "3               3         NaN   \n",
              "4               4         NaN   \n",
              "...           ...         ...   \n",
              "12565       12565         1.0   \n",
              "12566       12566         1.0   \n",
              "12567       12567         1.0   \n",
              "12568       12568         1.0   \n",
              "12569       12569         1.0   \n",
              "\n",
              "                                                    text         target  \\\n",
              "0      نصح نوم ليس تناول طعام موقع مثالي اقامة قبل رح...           موقع   \n",
              "1      كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...         الغرفة   \n",
              "2      كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...       الموظفون   \n",
              "3      كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...  بوفيه الإفطار   \n",
              "4      كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...    وجبة العشاء   \n",
              "...                                                  ...            ...   \n",
              "12565  كان منطقة طعام مقسم الى قسم كان طعام عادي حيث ...        الطعام    \n",
              "12566  شر نهاية اسبوع اسف مطعم حاءز على جاءزة لا فتح ...         أسعار    \n",
              "12567  تمام كما كان خلال زيارة ثلاث ماضي راءع قد جاء ...    فريق العمل    \n",
              "12568  نظافة سيء حمام قذر موقع دقيقة الى اقرب محطة قط...    فريق العمل    \n",
              "12569  نظافة سيء حمام قذر موقع دقيقة الى اقرب محطة قط...       الإفطار    \n",
              "\n",
              "                  category  polarity  sentiment  \n",
              "0         LOCATION#GENERAL  positive          2  \n",
              "1            ROOMS#GENERAL  positive          2  \n",
              "2          SERVICE#GENERAL  positive          2  \n",
              "3      FOOD_DRINKS#QUALITY  positive          2  \n",
              "4       FOOD_DRINKS#PRICES  negative          0  \n",
              "...                    ...       ...        ...  \n",
              "12565   FACILITIES#GENERAL   neutral          1  \n",
              "12566   FACILITIES#GENERAL   neutral          1  \n",
              "12567   FACILITIES#GENERAL   neutral          1  \n",
              "12568   FACILITIES#GENERAL   neutral          1  \n",
              "12569   FACILITIES#GENERAL   neutral          1  \n",
              "\n",
              "[12570 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8722102-e37d-480c-a17e-47c717b7ed05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>OutOfScope</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>نصح نوم ليس تناول طعام موقع مثالي اقامة قبل رح...</td>\n",
              "      <td>موقع</td>\n",
              "      <td>LOCATION#GENERAL</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...</td>\n",
              "      <td>الغرفة</td>\n",
              "      <td>ROOMS#GENERAL</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...</td>\n",
              "      <td>الموظفون</td>\n",
              "      <td>SERVICE#GENERAL</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...</td>\n",
              "      <td>بوفيه الإفطار</td>\n",
              "      <td>FOOD_DRINKS#QUALITY</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>كان غرفة ممتاز ذلك موظف في افطار مع ذلك قد كان...</td>\n",
              "      <td>وجبة العشاء</td>\n",
              "      <td>FOOD_DRINKS#PRICES</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12565</th>\n",
              "      <td>12565</td>\n",
              "      <td>1.0</td>\n",
              "      <td>كان منطقة طعام مقسم الى قسم كان طعام عادي حيث ...</td>\n",
              "      <td>الطعام</td>\n",
              "      <td>FACILITIES#GENERAL</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12566</th>\n",
              "      <td>12566</td>\n",
              "      <td>1.0</td>\n",
              "      <td>شر نهاية اسبوع اسف مطعم حاءز على جاءزة لا فتح ...</td>\n",
              "      <td>أسعار</td>\n",
              "      <td>FACILITIES#GENERAL</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12567</th>\n",
              "      <td>12567</td>\n",
              "      <td>1.0</td>\n",
              "      <td>تمام كما كان خلال زيارة ثلاث ماضي راءع قد جاء ...</td>\n",
              "      <td>فريق العمل</td>\n",
              "      <td>FACILITIES#GENERAL</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12568</th>\n",
              "      <td>12568</td>\n",
              "      <td>1.0</td>\n",
              "      <td>نظافة سيء حمام قذر موقع دقيقة الى اقرب محطة قط...</td>\n",
              "      <td>فريق العمل</td>\n",
              "      <td>FACILITIES#GENERAL</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12569</th>\n",
              "      <td>12569</td>\n",
              "      <td>1.0</td>\n",
              "      <td>نظافة سيء حمام قذر موقع دقيقة الى اقرب محطة قط...</td>\n",
              "      <td>الإفطار</td>\n",
              "      <td>FACILITIES#GENERAL</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12570 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8722102-e37d-480c-a17e-47c717b7ed05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8722102-e37d-480c-a17e-47c717b7ed05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8722102-e37d-480c-a17e-47c717b7ed05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WmhCy_o48a7g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "iooA4HKk8Lk-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_test_split(aspect_df, test_size=0.1, stratify=aspect_df.polarity , random_state=42)"
      ],
      "metadata": {
        "id": "lWDfKnhNxvoU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HotelReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, auxilaries, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.auxilaries = auxilaries\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    auxilary = str(self.auxilaries[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      auxilary,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=True,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'auxilary': auxilary,\n",
        "      'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "OpsGiHOH8R1I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = HotelReviewDataset(\n",
        "    reviews=df.text.to_numpy(),\n",
        "    auxilaries=df['target'].to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "metadata": {
        "id": "a8E3Bi6L8ZVc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYsWGu6I8j0R",
        "outputId": "052d7c53-c075-42f5-e2ee-02ff4f766763"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UeXMro8J_tj",
        "outputId": "63f2419b-b537-4ef7-b87d-6b809389634f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fc1083998d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.out.to('cuda')  \n",
        "  def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids=token_type_ids\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "AZIj7qEb9iwB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "id": "F4K6tftNUYL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9672e0b6-6473-48ec-c012-fcdf331737e1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'auxilary', 'token_type_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "GMztTysrUwYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3f5d3a-251a-4bc5-ed17-d357c1364d9b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "token_type_ids = data['token_type_ids'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length\n",
        "print(token_type_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsv6J83y_d5R",
        "outputId": "34ab33c0-d971-429f-9a63-d63f961e6d1e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n",
            "torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(model(input_ids, attention_mask, token_type_ids), dim=1)"
      ],
      "metadata": {
        "id": "MzDWRaRGU22Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e11c4d1-92d2-46e3-fea9-32f06e4b9a52"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3435, 0.6223, 0.0342],\n",
              "        [0.2659, 0.6244, 0.1096],\n",
              "        [0.2253, 0.6958, 0.0789],\n",
              "        [0.2518, 0.6965, 0.0517],\n",
              "        [0.3020, 0.5151, 0.1828],\n",
              "        [0.3913, 0.3164, 0.2924],\n",
              "        [0.6233, 0.2638, 0.1129],\n",
              "        [0.2379, 0.6359, 0.1263],\n",
              "        [0.2584, 0.4702, 0.2714],\n",
              "        [0.2774, 0.5579, 0.1646],\n",
              "        [0.4738, 0.4118, 0.1144],\n",
              "        [0.4364, 0.4093, 0.1542],\n",
              "        [0.2636, 0.4993, 0.2370],\n",
              "        [0.4515, 0.4060, 0.1424],\n",
              "        [0.3748, 0.5322, 0.0929],\n",
              "        [0.4490, 0.5056, 0.0454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ZhP2AuoSH-kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "ZkVnTLkBIQfI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False,weight_decay=0.001)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv5z0P2GH-J_",
        "outputId": "787bdf66-3862-4c92-93b7-22b2ed639d69"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  \n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids=token_type_ids\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "d5EJM8nOISvX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "N_4KdUC4IYqf"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state_ARABERT.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "metadata": {
        "id": "d_JCoe5QU_Ni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ac29b8-62ce-4fee-c737-d23b03394bcc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9530885893914659 accuracy 0.576681693626801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 1.1704729305037969 accuracy 0.4932378679395386\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8300012912032968 accuracy 0.6574737028197648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7933988292005998 accuracy 0.6785998408910103\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6329398870383952 accuracy 0.7313709891275524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6418241849051246 accuracy 0.7549721559268099\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5339020503432317 accuracy 0.7842305312472376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6222727317598802 accuracy 0.7621320604614161\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.45315672163614784 accuracy 0.8255988685582957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.45072619235025174 accuracy 0.8257756563245824\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3852898325681644 accuracy 0.8595421196853177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.4250145455044282 accuracy 0.8385043754972157\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3403483778251451 accuracy 0.8750110492353929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.43332517346296506 accuracy 0.8504375497215593\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.3093327287923924 accuracy 0.8894192521877485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.4374390540385171 accuracy 0.8599840891010343\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2865119322379367 accuracy 0.898170246618934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.3981479527192968 accuracy 0.8615751789976134\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2719324114929758 accuracy 0.9028551224255281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.4101519383242519 accuracy 0.8647573587907718\n",
            "\n",
            "CPU times: user 40min 45s, sys: 1min 7s, total: 41min 52s\n",
            "Wall time: 42min 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SsfKrCEOT4un"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_acc = np.array([item.cpu() for item in history['train_acc']])\n",
        "val_acc = np.array([item.cpu() for item in history['val_acc']])\n",
        "\n",
        "plt.plot(train_acc, label='train accuracy')\n",
        "plt.plot(val_acc, label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RJN0aZe0VRDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2b15cad9-f4a5-4839-d82a-ef7d39f1033d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_excel(\"/content/drive/MyDrive/dataxlsx/AR_HOTE_SB1_TEST_GOLD.xlsx\")\n",
        "\n",
        "test_df = test_df.drop(['rid', 'id', 'from', 'to'], axis=1)\n",
        "test_df = test_df.fillna(method='ffill')\n",
        "test_df['sentiment'] = test_df.polarity.apply(to_sentiment)\n",
        "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "m6uYbhALVZMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888fe826-8948-4f1b-e0c2-cd69608d3f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAq7anMRTZc",
        "outputId": "704771b7-e243-49f2-9e97-ecc513f5d338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2606, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(test_df)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "metadata": {
        "id": "3eSxThjwVig4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2a4476-8708-4b9f-ff3f-a1a34a86196b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8867996930161166"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  auxilary_texts = []\n",
        "  targets = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      auxilaries = d[\"auxilary\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids=token_type_ids\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      auxilary_texts.extend(auxilaries)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, auxilary_texts, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "QHIIytd7ftNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_review_texts,y_auxilary_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "metadata": {
        "id": "Dbej_HiMVxtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827a861d-69d7-416e-d68c-ec2175e4cc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "id": "7WRWB10gV0vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5e345e-f913-44cb-9707-82a4d1e3e93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.92      0.91       927\n",
            "     neutral       0.49      0.43      0.46       169\n",
            "    positive       0.91      0.92      0.92      1510\n",
            "\n",
            "    accuracy                           0.89      2606\n",
            "   macro avg       0.77      0.76      0.76      2606\n",
            "weighted avg       0.88      0.89      0.89      2606\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted labels\")\n",
        "plt.ylabel(\"True labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noOtG34AJpQY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "3a6aab3d-7cb9-41cd-b234-06faf74f8987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx0AAAK9CAYAAABB8gHJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABb/ElEQVR4nO3deVhV5d7G8XuDgIgC4gDigDikkuZYhrNJjpWmHbOo0BwasJwzT2kOFWVOkVM2qJWWDWpqZZHmTM44ZeaMpuCAgBODsN8/fN1n79ACW8sN+P28176uw7OevdZv7/Pq8cf9PGtZrFarVQAAAABgEhdnFwAAAACgcKPpAAAAAGAqmg4AAAAApqLpAAAAAGAqmg4AAAAApqLpAAAAAGAqmg4AAAAApqLpAAAAAGAqmg4AAAAApqLpAIDr2L9/v9q2bSsfHx9ZLBYtXrzY0PMfOXJEFotFc+bMMfS8BVmrVq3UqlUrZ5cBADABTQeAfOvgwYN65plnVKVKFRUtWlTe3t5q2rSp3n33XV2+fNnUa0dERGjXrl1644039Omnn6pRo0amXu9W6tmzpywWi7y9va/7Pe7fv18Wi0UWi0UTJkzI8/lPnDih0aNHKy4uzoBqAQCFQRFnFwAA1/Pdd9/pP//5jzw8PPTUU0+pdu3aysjI0Lp16zRs2DDt2bNHs2bNMuXaly9fVmxsrF555RX179/flGsEBQXp8uXLcnNzM+X8/6RIkSK6dOmSli5dqu7duzscmzdvnooWLaq0tLSbOveJEyc0ZswYVa5cWfXq1cv1+3766aebuh4AIP+j6QCQ7xw+fFg9evRQUFCQVq5cqXLlytmORUZG6sCBA/ruu+9Mu/7p06clSb6+vqZdw2KxqGjRoqad/594eHioadOm+vzzz3M0HfPnz1enTp30zTff3JJaLl26pGLFisnd3f2WXA8AcOuxvApAvjN+/HhduHBBH330kUPDcU21atU0YMAA289XrlzRuHHjVLVqVXl4eKhy5cr673//q/T0dIf3Va5cWQ888IDWrVune+65R0WLFlWVKlX0ySef2OaMHj1aQUFBkqRhw4bJYrGocuXKkq4uS7r2n+2NHj1aFovFYSwmJkbNmjWTr6+vihcvrho1aui///2v7fiN9nSsXLlSzZs3l5eXl3x9fdW5c2ft3bv3utc7cOCAevbsKV9fX/n4+KhXr166dOnSjb/Yv3j88cf1ww8/KDk52Ta2efNm7d+/X48//niO+UlJSRo6dKjq1Kmj4sWLy9vbWx06dNCOHTtsc1atWqW7775bktSrVy/bMq1rn7NVq1aqXbu2tm7dqhYtWqhYsWK27+WvezoiIiJUtGjRHJ+/Xbt2KlmypE6cOJHrzwoAcC6aDgD5ztKlS1WlShU1adIkV/P79OmjUaNGqUGDBpo8ebJatmypqKgo9ejRI8fcAwcO6JFHHtH999+viRMnqmTJkurZs6f27NkjSeratasmT54sSXrsscf06aefasqUKXmqf8+ePXrggQeUnp6usWPHauLEiXrooYe0fv36v33fzz//rHbt2unUqVMaPXq0Bg8erA0bNqhp06Y6cuRIjvndu3fX+fPnFRUVpe7du2vOnDkaM2ZMruvs2rWrLBaLFi5caBubP3++atasqQYNGuSYf+jQIS1evFgPPPCAJk2apGHDhmnXrl1q2bKlrQGoVauWxo4dK0nq16+fPv30U3366adq0aKF7Txnz55Vhw4dVK9ePU2ZMkWtW7e+bn3vvvuuypQpo4iICGVlZUmS3n//ff3000967733FBgYmOvPCgBwMisA5CMpKSlWSdbOnTvnan5cXJxVkrVPnz4O40OHDrVKsq5cudI2FhQUZJVkXbNmjW3s1KlTVg8PD+uQIUNsY4cPH7ZKsr7zzjsO54yIiLAGBQXlqOG1116z2v91OnnyZKsk6+nTp29Y97VrzJ492zZWr149a9myZa1nz561je3YscPq4uJifeqpp3Jc7+mnn3Y458MPP2wtVarUDa9p/zm8vLysVqvV+sgjj1jbtGljtVqt1qysLGtAQIB1zJgx1/0O0tLSrFlZWTk+h4eHh3Xs2LG2sc2bN+f4bNe0bNnSKsk6c+bM6x5r2bKlw9iPP/5olWR9/fXXrYcOHbIWL17c2qVLl3/8jACA/IWkA0C+kpqaKkkqUaJEruZ///33kqTBgwc7jA8ZMkSScuz9CAkJUfPmzW0/lylTRjVq1NChQ4duuua/urYX5Ntvv1V2dnau3nPy5EnFxcWpZ8+e8vPzs43fdddduv/++22f096zzz7r8HPz5s119uxZ23eYG48//rhWrVqlhIQErVy5UgkJCdddWiVd3Qfi4nL1fzaysrJ09uxZ29Kxbdu25fqaHh4e6tWrV67mtm3bVs8884zGjh2rrl27qmjRonr//fdzfS0AQP5A0wEgX/H29pYknT9/Plfzjx49KhcXF1WrVs1hPCAgQL6+vjp69KjDeKVKlXKco2TJkjp37txNVpzTo48+qqZNm6pPnz7y9/dXjx499OWXX/5tA3Ktzho1auQ4VqtWLZ05c0YXL150GP/rZylZsqQk5emzdOzYUSVKlNCCBQs0b9483X333Tm+y2uys7M1efJkVa9eXR4eHipdurTKlCmjnTt3KiUlJdfXLF++fJ42jU+YMEF+fn6Ki4tTdHS0ypYtm+v3AgDyB5oOAPmKt7e3AgMDtXv37jy9768buW/E1dX1uuNWq/Wmr3Ftv8E1np6eWrNmjX7++Wc9+eST2rlzpx599FHdf//9Oeb+G//ms1zj4eGhrl27au7cuVq0aNENUw5JevPNNzV48GC1aNFCn332mX788UfFxMTozjvvzHWiI139fvJi+/btOnXqlCRp165deXovACB/oOkAkO888MADOnjwoGJjY/9xblBQkLKzs7V//36H8cTERCUnJ9vuRGWEkiVLOtzp6Zq/pimS5OLiojZt2mjSpEn67bff9MYbb2jlypX65Zdfrnvua3Xu27cvx7Hff/9dpUuXlpeX17/7ADfw+OOPa/v27Tp//vx1N99f8/XXX6t169b66KOP1KNHD7Vt21ZhYWE5vpPcNoC5cfHiRfXq1UshISHq16+fxo8fr82bNxt2fgDArUHTASDfeemll+Tl5aU+ffooMTExx/GDBw/q3XfflXR1eZCkHHeYmjRpkiSpU6dOhtVVtWpVpaSkaOfOnbaxkydPatGiRQ7zkpKScrz32kPy/nob32vKlSunevXqae7cuQ7/iN+9e7d++ukn2+c0Q+vWrTVu3DhNnTpVAQEBN5zn6uqaI0X56quv9OeffzqMXWuOrteg5dXw4cMVHx+vuXPnatKkSapcubIiIiJu+D0CAPInHg4IIN+pWrWq5s+fr0cffVS1atVyeCL5hg0b9NVXX6lnz56SpLp16yoiIkKzZs1ScnKyWrZsqU2bNmnu3Lnq0qXLDW/HejN69Oih4cOH6+GHH9aLL76oS5cuacaMGbrjjjscNlKPHTtWa9asUadOnRQUFKRTp05p+vTpqlChgpo1a3bD87/zzjvq0KGDQkND1bt3b12+fFnvvfeefHx8NHr0aMM+x1+5uLjo1Vdf/cd5DzzwgMaOHatevXqpSZMm2rVrl+bNm6cqVao4zKtatap8fX01c+ZMlShRQl5eXmrcuLGCg4PzVNfKlSs1ffp0vfbaa7Zb+M6ePVutWrXSyJEjNX78+DydDwDgPCQdAPKlhx56SDt37tQjjzyib7/9VpGRkXr55Zd15MgRTZw4UdHR0ba5H374ocaMGaPNmzdr4MCBWrlypUaMGKEvvvjC0JpKlSqlRYsWqVixYnrppZc0d+5cRUVF6cEHH8xRe6VKlfTxxx8rMjJS06ZNU4sWLbRy5Ur5+Pjc8PxhYWFavny5SpUqpVGjRmnChAm69957tX79+jz/g90M//3vfzVkyBD9+OOPGjBggLZt26bvvvtOFStWdJjn5uamuXPnytXVVc8++6wee+wxrV69Ok/XOn/+vJ5++mnVr19fr7zyim28efPmGjBggCZOnKhff/3VkM8FADCfxZqXHYcAAAAAkEckHQAAAABMRdMBAAAAwFQ0HQAAAABMRdMBAAAAwFQ0HQAAAABMRdMBAAAAwFQ0HQAAAABMVSifSN52Gg+MAm7GkmfudXYJQIGUlpnl7BKAAsfX09XZJdyQZ/3+Trv25e1TnXZtM5F0AAAAADBVoUw6AAAAgJtm4ffyRuMbBQAAAGAqmg4AAAAApmJ5FQAAAGDPYnF2BYUOSQcAAAAAU5F0AAAAAPbYSG44vlEAAAAApiLpAAAAAOyxp8NwJB0AAAAATEXTAQAAAMBULK8CAAAA7LGR3HB8owAAAABMRdIBAAAA2GMjueFIOgAAAACYiqYDAAAAgKlYXgUAAADYYyO54fhGAQAAAJiKpAMAAACwx0Zyw5F0AAAAADAVSQcAAABgjz0dhuMbBQAAAGAqmg4AAAAApmJ5FQAAAGCPjeSGI+kAAAAAYCqSDgAAAMAeG8kNxzcKAAAAwFQ0HQAAAABMxfIqAAAAwB4byQ1H0gEAAADAVCQdAAAAgD02khuObxQAAACAqUg6AAAAAHskHYbjGwUAAABgKpoOAAAAAKZieRUAAABgz4Vb5hqNpAMAAACAqUg6AAAAAHtsJDcc3ygAAAAAU9F0AAAAADAVy6sAAAAAexY2khuNpAMAAACAqUg6AAAAAHtsJDcc3ygAAAAAU5F0AAAAAPbY02E4kg4AAAAApqLpAAAAAGAqllcBAAAA9thIbji+UQAAAACmIukAAAAA7LGR3HAkHQAAAABMRdMBAAAAwFQsrwIAAADssZHccHyjAAAAAExF0gEAAADYYyO54Ug6AAAAAJiKpAMAAACwx54Ow/GNAgAAADAVTQcAAAAAU7G8CgAAALDHRnLDkXQAAAAAMBVJBwAAAGCPjeSG4xsFAAAAYCqaDgAAAACmYnkVAAAAYI/lVYbjGwUAAABgKpIOAAAAwB63zDUcSQcAAAAAU9F0AAAAADAVy6sAAAAAe2wkNxzfKAAAAABTkXQAAAAA9thIbjiSDgAAAACmIukAAAAA7LGnw3B8owAAAABMRdMBAAAAwFQsrwIAAADssZHccCQdAAAAQAG0Zs0aPfjggwoMDJTFYtHixYttxzIzMzV8+HDVqVNHXl5eCgwM1FNPPaUTJ044nCMpKUnh4eHy9vaWr6+vevfurQsXLjjM2blzp5o3b66iRYuqYsWKGj9+fJ5rpekAAAAA7FgsFqe98uLixYuqW7eupk2bluPYpUuXtG3bNo0cOVLbtm3TwoULtW/fPj300EMO88LDw7Vnzx7FxMRo2bJlWrNmjfr162c7npqaqrZt2yooKEhbt27VO++8o9GjR2vWrFl5qpXlVQAAAEAB1KFDB3Xo0OG6x3x8fBQTE+MwNnXqVN1zzz2Kj49XpUqVtHfvXi1fvlybN29Wo0aNJEnvvfeeOnbsqAkTJigwMFDz5s1TRkaGPv74Y7m7u+vOO+9UXFycJk2a5NCc/BOSDgAAACCfSE9PV2pqqsMrPT3dkHOnpKTIYrHI19dXkhQbGytfX19bwyFJYWFhcnFx0caNG21zWrRoIXd3d9ucdu3aad++fTp37lyur03TAQAAANhx5vKqqKgo+fj4OLyioqL+9WdKS0vT8OHD9dhjj8nb21uSlJCQoLJlyzrMK1KkiPz8/JSQkGCb4+/v7zDn2s/X5uQGy6sAAACAfGLEiBEaPHiww5iHh8e/OmdmZqa6d+8uq9WqGTNm/Ktz3SyaDgAAAMCeE++Y6+Hh8a+bDHvXGo6jR49q5cqVtpRDkgICAnTq1CmH+VeuXFFSUpICAgJscxITEx3mXPv52pzcYHkVAAAAUAhdazj279+vn3/+WaVKlXI4HhoaquTkZG3dutU2tnLlSmVnZ6tx48a2OWvWrFFmZqZtTkxMjGrUqKGSJUvmuhaaDgAAAMBOQbll7oULFxQXF6e4uDhJ0uHDhxUXF6f4+HhlZmbqkUce0ZYtWzRv3jxlZWUpISFBCQkJysjIkCTVqlVL7du3V9++fbVp0yatX79e/fv3V48ePRQYGChJevzxx+Xu7q7evXtrz549WrBggd59990cS8D+CcurAAAAgAJoy5Ytat26te3na41ARESERo8erSVLlkiS6tWr5/C+X375Ra1atZIkzZs3T/3791ebNm3k4uKibt26KTo62jbXx8dHP/30kyIjI9WwYUOVLl1ao0aNytPtciWaDgAAAKBAatWqlaxW6w2P/92xa/z8/DR//vy/nXPXXXdp7dq1ea7PHk0HAAAAYCevy5zwz9jTAQAAAMBUJB0AAACAHZIO45F0AAAAADAVTQcAAAAAU7G8CgAAALDD8irjkXQAAAAAMBVJBwAAAGCPoMNwNB34V1ws0pN3V1CbGqVVspi7zl7MUMzvpzVvy5+2OUPvq6q2tco4vG/z0WS9sux328+fPFlfAd4eDnM+io3Xgm0nzP0AQD538eIFTYt+VytX/KykpLOqWStEL738X9Wuc5ezSwPyjVOJiZr27kRtWL9W6WlpqlCxkkaOeUO17qwtSfpgxlTF/PiDEhMS5ObmppohIXq2/wDVrlPXyZUDtw+aDvwr3RsE6oHa/npnxUEdTbqsO8p6ach9VXUxI0uLdybY5m0+mqwJKw/afs7Mys5xrrkbj+n7307Zfr6ckWVu8UABMHrUqzqwf7/eeGu8ypQpq++WLdEzfXpp4ZLv5e/v7+zyAKdLTU1Rv57hanD3PZoy9X2V9PNT/NGjKuHtbZtTKaiyhr78ispXqKj0tDR9Pu8TvfhcX32zZLlK+vk5sXrkV+zpMB5NB/6VkIASij18TpuOJkuSEs+nq1X1UqpR1sthXmZWts5dyvzbc13KyPrHOcDtJC0tTStiftKU96arYaO7JUnPRb6g1at+0VdfzFf/AYOcXCHgfJ/O/khlAwI0auybtrHA8hUc5rTr+IDDzwOGDNeSRd/owP59urtx6C2pE7jdObXpOHPmjD7++GPFxsYqIeHqb8UDAgLUpEkT9ezZU2XKlPmHM8DZfks4r44h/irvU1R/pqSpSqliql2uhN5ff9Rh3l3lvfVlr4Y6n35FcX+mas6vx3Q+/YrDnEcbBir87vI6dT5Dv+w/o2/iTirbeis/DZC/ZGVdUVZWljw8HJceenh4aPv2bU6qCshf1qxeqXtDm2nE0IHavnWLypQtq27dH1OXbv+57vzMzAwt/uZLFS9eQtXvqHmLqwVuX05rOjZv3qx27dqpWLFiCgsL0x133CFJSkxMVHR0tN566y39+OOPatSo0d+eJz09Xenp6Q5j2ZkZcnFzN612/M+CrSdUzM1VH4XXVXa2VS4uFs359ZhW/nHWNmdLfLLWHUpSQmqaAn2Kqte9FfXGgzU18Jvdtqbi250ntf/0JZ1Pv6KQgOJ6+t5K8ivmnqN5AW4nXl7FVbdefc2aOV3BVaqoVKnS+uH7Zdq5I04VK1VydnlAvnDi+HEt/OoLPfZEhHr26affdu/WpPFvys3NTZ0e6mKbt27NKr06fIjS0tJUunQZvTfzQ/mWLOm8wpGvsbzKeBar1eqU3yXfe++9qlu3rmbOnJnjv1ir1apnn31WO3fuVGxs7N+eZ/To0RozZozDWJUOvVW1Ux/Da0ZOraqVUt8mlfTBhngdSbqkqqW99FzzIL2/7qhi9p257nsCvD30yZP19dK3vynueOp157SrVUYDWgar86zNyiTuuGWWPHOvs0vAXxyLj9drI/+rrVs2y9XVVTVrhSiocmXt/W2PFi/9wdnl4f+lZbIHzVmaNrpLtUJq68NP5tvGJr79hn7bs1sfffK5bezy5Us6c/q0kpOT9e3Cr7Rl00Z9/NkX8vMr5YyyIcnX09XZJdxQySfmOe3a5z4Ld9q1zeS053Ts2LFDgwYNum4nabFYNGjQIMXFxf3jeUaMGKGUlBSHV3Dbp0yoGNfTt0klfbHthFYdOKsjSZe14o8zWhiXoB4Ny9/wPQmp6Uq+nKnyPkVvOOf3xAsq4uoi/7/c0Qq43VSsVEkfz/1MsZu368cVqzR/wde6cuWKKlSo6OzSgHyhdJkyCq5a1WGscnBVJZ486TDm6VlMFSsFqc5ddfXq6Nfl6uqqJYu+uZWlogCxWCxOexVWTms6AgICtGnTphse37RpU67uzOLh4SFvb2+HF0urbh0PNxf9NSvLtlr1d39mSnu5y7toEZ29eONN41VLF1NWtlXJl9lYDkhSsWLFVKZMWaWmpCh2/Tq1at3G2SUB+cJddRvo6JHDDmPxR48ooFzg377ParUqMyPDzNIA2HHano6hQ4eqX79+2rp1q9q0aWNrMBITE7VixQp98MEHmjBhgrPKQy79ejhZjzUK1KkL6TqadFnVShdT13rl9OPe05Kkom4uevLuClp7MEnnLmWqnI+H+oZW0omUNG2NT5Yk1fIvrpr+xbXjz1RdysxSSEBxPdu0slb+cUYX0lmygNvb+nVrJatVQcHBOhYfr8kTxqtycBV1frirs0sD8oXHnnhKfXqGa86H76tN2/b6bfcuLf7mK40YOVrS1WVVsz94X81b3afSpUsrOTlZXy+Yr9OnEtXm/nbOLR64jTit6YiMjFTp0qU1efJkTZ8+XVlZV/9x6erqqoYNG2rOnDnq3r27s8pDLk1be1gRjSvqhZbB8vV009mLGfp+T6I+23z14YDZ2VYFlyqm+2uUkZeHq85ezNS2Y8mas/G4ba9GZla2WlUvpSfvqSA3VxclpKZp4Y6T+ibu5N9dGrgtXLhwXtFTJikxIUE+Pr5qc39bvTBgkNzc3JxdGpAvhNSuo/GTojU9erI+mjVDgeUraNCwl9W+04OSJBcXVx09cljfDxmg5ORz8vH1Va07a+v9jz9VlWrVnVw98qvCvMzJWZy2kdxeZmamzpy5uum4dOnS//p/TNtO+9WIsoDbDhvJgZvDRnIg7/LzRvJST33+z5NMcvaTx5x2bTPli4cDurm5qVy5cs4uAwAAAJAIOgzntI3kAAAAAG4P+SLpAAAAAPIL9nQYj6QDAAAAgKloOgAAAACYiuVVAAAAgB2WVxmPpAMAAACAqUg6AAAAADskHcYj6QAAAABgKpoOAAAAAKZieRUAAABgj9VVhiPpAAAAAGAqkg4AAADADhvJjUfSAQAAAMBUJB0AAACAHZIO45F0AAAAADAVTQcAAAAAU7G8CgAAALDD8irjkXQAAAAAMBVJBwAAAGCHpMN4JB0AAAAATEXTAQAAAMBULK8CAAAA7LG6ynAkHQAAAABMRdIBAAAA2GEjufFIOgAAAACYiqQDAAAAsEPSYTySDgAAAACmoukAAAAAYCqWVwEAAAB2WF5lPJIOAAAAAKYi6QAAAADsEXQYjqQDAAAAgKloOgAAAACYiuVVAAAAgB02khuPpAMAAACAqUg6AAAAADskHcYj6QAAAABgKpoOAAAAAKZieRUAAABgh+VVxiPpAAAAAGAqkg4AAADADkmH8Ug6AAAAAJiKpAMAAACwR9BhOJIOAAAAAKai6QAAAABgKpZXAQAAAHbYSG48kg4AAAAApiLpAAAAAOyQdBiPpAMAAACAqWg6AAAAAJiK5VUAAACAHVZXGY+kAwAAAICpSDoAAAAAO2wkNx5JBwAAAABTkXQAAAAAdgg6jEfSAQAAAMBUNB0AAAAATMXyKgAAAMAOG8mNR9IBAAAAwFQ0HQAAAIAdi8V5r7xYs2aNHnzwQQUGBspisWjx4sUOx61Wq0aNGqVy5crJ09NTYWFh2r9/v8OcpKQkhYeHy9vbW76+vurdu7cuXLjgMGfnzp1q3ry5ihYtqooVK2r8+PF5/k5pOgAAAIAC6OLFi6pbt66mTZt23ePjx49XdHS0Zs6cqY0bN8rLy0vt2rVTWlqabU54eLj27NmjmJgYLVu2TGvWrFG/fv1sx1NTU9W2bVsFBQVp69ateueddzR69GjNmjUrT7WypwMAAADIJ9LT05Wenu4w5uHhIQ8PjxxzO3TooA4dOlz3PFarVVOmTNGrr76qzp07S5I++eQT+fv7a/HixerRo4f27t2r5cuXa/PmzWrUqJEk6b333lPHjh01YcIEBQYGat68ecrIyNDHH38sd3d33XnnnYqLi9OkSZMcmpN/QtIBAAAA2HFxsTjtFRUVJR8fH4dXVFRUnj/D4cOHlZCQoLCwMNuYj4+PGjdurNjYWElSbGysfH19bQ2HJIWFhcnFxUUbN260zWnRooXc3d1tc9q1a6d9+/bp3Llzua6HpAMAAADIJ0aMGKHBgwc7jF0v5fgnCQkJkiR/f3+HcX9/f9uxhIQElS1b1uF4kSJF5Ofn5zAnODg4xzmuHStZsmSu6qHpAAAAAOw48465N1pKVdCxvAoAAAAoZAICAiRJiYmJDuOJiYm2YwEBATp16pTD8StXrigpKclhzvXOYX+N3KDpAAAAAOxYLBanvYwSHBysgIAArVixwjaWmpqqjRs3KjQ0VJIUGhqq5ORkbd261TZn5cqVys7OVuPGjW1z1qxZo8zMTNucmJgY1ahRI9dLqySaDgAAAKBAunDhguLi4hQXFyfp6ubxuLg4xcfHy2KxaODAgXr99de1ZMkS7dq1S0899ZQCAwPVpUsXSVKtWrXUvn179e3bV5s2bdL69evVv39/9ejRQ4GBgZKkxx9/XO7u7urdu7f27NmjBQsW6N13382x7+SfsKcDAAAAKIC2bNmi1q1b236+1ghERERozpw5eumll3Tx4kX169dPycnJatasmZYvX66iRYva3jNv3jz1799fbdq0kYuLi7p166bo6GjbcR8fH/3000+KjIxUw4YNVbp0aY0aNSpPt8uVJIvVarX+y8+b77Sd9quzSwAKpCXP3OvsEoACKS0zy9klAAWOr6ers0u4oTojY5x27V3j7nfatc3E8ioAAAAApmJ5FQAAAGDHyA3duIqkAwAAAICpaDoAAAAAmIrlVQAAAIAdllcZj6QDAAAAgKlIOgAAAAA7BB3GI+kAAAAAYCqSDgAAAMAOezqMR9IBAAAAwFQ0HQAAAABMxfIqAAAAwA6rq4xH0gEAAADAVCQdAAAAgB02khuPpAMAAACAqWg6AAAAAJiK5VUAAACAHVZXGY+kAwAAAICpSDoAAAAAO2wkNx5JBwAAAABTkXQAAAAAdgg6jEfSAQAAAMBUNB0AAAAATMXyKgAAAMAOG8mNR9IBAAAAwFQkHQAAAIAdgg7jFcqmY3Hfxs4uASiQLmdkObsEoEDiHygA8PdYXgUAAADAVIUy6QAAAABuFhvJjUfSAQAAAMBUJB0AAACAHYIO45F0AAAAADAVSQcAAABghz0dxiPpAAAAAGAqmg4AAAAApmJ5FQAAAGCH1VXGI+kAAAAAYCqSDgAAAMAOG8mNR9IBAAAAwFQ0HQAAAABMxfIqAAAAwA7Lq4xH0gEAAADAVCQdAAAAgB2CDuORdAAAAAAwFU0HAAAAAFOxvAoAAACww0Zy45F0AAAAADAVSQcAAABgh6DDeCQdAAAAAExF0gEAAADYYU+H8Ug6AAAAAJiKpgMAAACAqVheBQAAANhhdZXxSDoAAAAAmIqkAwAAALDjQtRhOJIOAAAAAKai6QAAAABgKpZXAQAAAHZYXWU8kg4AAAAApiLpAAAAAOzwRHLjkXQAAAAAMBVJBwAAAGDHhaDDcCQdAAAAAExF0wEAAADAVCyvAgAAAOywkdx4JB0AAAAATEXSAQAAANgh6DAeSQcAAAAAU9F0AAAAADAVy6sAAAAAOxaxvspoJB0AAAAATEXSAQAAANjhieTGI+kAAAAAYCqSDgAAAMAODwc0HkkHAAAAAFPRdAAAAAAwFcurAAAAADusrjIeSQcAAAAAU9F0AAAAAHZcLBanvfIiKytLI0eOVHBwsDw9PVW1alWNGzdOVqvVNsdqtWrUqFEqV66cPD09FRYWpv379zucJykpSeHh4fL29pavr6969+6tCxcuGPJdXkPTAQAAABRAb7/9tmbMmKGpU6dq7969evvttzV+/Hi99957tjnjx49XdHS0Zs6cqY0bN8rLy0vt2rVTWlqabU54eLj27NmjmJgYLVu2TGvWrFG/fv0MrdVitW+FColLGYXuIwG3RPqVbGeXABRIrP8G8s7X09XZJdxQ14+2Ou3aC3s3zPXcBx54QP7+/vroo49sY926dZOnp6c+++wzWa1WBQYGasiQIRo6dKgkKSUlRf7+/pozZ4569OihvXv3KiQkRJs3b1ajRo0kScuXL1fHjh11/PhxBQYGGvK5SDoAAAAAOxaL817p6elKTU11eKWnp1+3ziZNmmjFihX6448/JEk7duzQunXr1KFDB0nS4cOHlZCQoLCwMNt7fHx81LhxY8XGxkqSYmNj5evra2s4JCksLEwuLi7auHGjYd8pTQcAAACQT0RFRcnHx8fhFRUVdd25L7/8snr06KGaNWvKzc1N9evX18CBAxUeHi5JSkhIkCT5+/s7vM/f3992LCEhQWXLlnU4XqRIEfn5+dnmGIFb5gIAAAB2nPlE8hEjRmjw4MEOYx4eHted++WXX2revHmaP3++7rzzTsXFxWngwIEKDAxURETErSg312g6AAAAgHzCw8Pjhk3GXw0bNsyWdkhSnTp1dPToUUVFRSkiIkIBAQGSpMTERJUrV872vsTERNWrV0+SFBAQoFOnTjmc98qVK0pKSrK93wgsrwIAAADsOHNPR15cunRJLi6O/5x3dXVVdvbVG8MEBwcrICBAK1assB1PTU3Vxo0bFRoaKkkKDQ1VcnKytm793+b5lStXKjs7W40bN77JbzAnkg4AAACgAHrwwQf1xhtvqFKlSrrzzju1fft2TZo0SU8//bSkq8vEBg4cqNdff13Vq1dXcHCwRo4cqcDAQHXp0kWSVKtWLbVv3159+/bVzJkzlZmZqf79+6tHjx6G3blKoukAAAAACqT33ntPI0eO1PPPP69Tp04pMDBQzzzzjEaNGmWb89JLL+nixYvq16+fkpOT1axZMy1fvlxFixa1zZk3b5769++vNm3ayMXFRd26dVN0dLShtfKcDgA2PKcDuDk8pwPIu/z8nI5H52532rUXRNR32rXNxJ4OAAAAAKZieRUAAABgh/DSeCQdAAAAAExF0wEAAADAVIYsr0pOTpavr68RpwIAAACcyplPJC+s8px0vP3221qwYIHt5+7du6tUqVIqX768duzYYWhxAAAAAAq+PDcdM2fOVMWKFSVJMTExiomJ0Q8//KAOHTpo2LBhhhcIAAAA3EouFue9Cqs8L69KSEiwNR3Lli1T9+7d1bZtW1WuXNnQR6UDAAAAKBzynHSULFlSx44dkyQtX75cYWFhkiSr1aqsrCxjqwMAAABuMYvF4rRXYZXnpKNr1656/PHHVb16dZ09e1YdOnSQJG3fvl3VqlUzvEAAAAAABVuem47JkyercuXKOnbsmMaPH6/ixYtLkk6ePKnnn3/e8AIBAAAAFGwWq9VqdXYRRruUUeg+EnBLpF/JdnYJQIFUiFdEAKbx9XR1dgk39OQ8592R9dPwuk67tplylXQsWbIk1yd86KGHbroYAAAAAIVPrpqOLl265OpkFouFzeQAAAAo0Arzhm5nyVXTkZ3NkgsAAAAANyfPt8y1l5aWZlQdAAAAAAqpPDcdWVlZGjdunMqXL6/ixYvr0KFDkqSRI0fqo48+MrxAAAAA4FbiieTGy3PT8cYbb2jOnDkaP3683N3dbeO1a9fWhx9+aGhxAAAAAAq+PDcdn3zyiWbNmqXw8HC5uv7vVmd169bV77//bmhxAAAAwK3GE8mNl+em488//7zuk8ezs7OVmZlpSFEAAAAACo88Nx0hISFau3ZtjvGvv/5a9evXN6QoAAAAwFksTnwVVrm6Za69UaNGKSIiQn/++aeys7O1cOFC7du3T5988omWLVtmRo0AAAAACrA8Jx2dO3fW0qVL9fPPP8vLy0ujRo3S3r17tXTpUt1///1m1AgAAACgAMtz0iFJzZs3V0xMjNG1AAAAAE7nUog3dDvLTTUdkrRlyxbt3btX0tV9Hg0bNjSsKAAAAACFR56bjuPHj+uxxx7T+vXr5evrK0lKTk5WkyZN9MUXX6hChQpG1wgAAADcMgQdxsvzno4+ffooMzNTe/fuVVJSkpKSkrR3715lZ2erT58+ZtQIAAAAoADLc9KxevVqbdiwQTVq1LCN1ahRQ++9956aN29uaHEAAAAACr48Nx0VK1a87kMAs7KyFBgYaEhRAAAAgLMU5ieDO0uel1e98847euGFF7Rlyxbb2JYtWzRgwABNmDDB0OIAAAAAFHwWq9Vq/adJJUuWdOj4Ll68qCtXrqhIkatBybX/7OXlpaSkJPOqzaVLGf/4kQBcR/qVbGeXABRI/FIUyDtfT1dnl3BDz3y9x2nXfv+RO512bTPlannVlClTTC4DAAAAQGGVq6YjIiLC7DoAAAAAFFI3/XBASUpLS1NGRobDmLe3978qCAAAAHAmnkhuvDw3HRcvXtTw4cP15Zdf6uzZszmOZ2VlGVIYCq4vF3yurxd8rhMn/pQkValaTf2ejVSz5i0kSenp6Zr0ztv6cfl3ysjIVGjTpvrvK6+pVOnSziwbcLouHcOUcPJEjvFu3R/TsBEj9dbrr2nzxl915vQpeXoWU5269RQ5YIgqB1dxQrVA/nEqMVHT3p2oDevXKj0tTRUqVtLIMW+o1p21bXMOHzqoae9O0ratm5V1JUvBVarqrYlTFFCOO28Ct0Kem46XXnpJv/zyi2bMmKEnn3xS06ZN059//qn3339fb731lhk1ooDx9/fXCwOHqFJQkGS1aumSxRr0YqS++Gqhqlarrgnjo7RuzWqNn/iuihcvrrfeHKchg17QnE8/d3bpgFPN/uxLZWf/7xc3Bw/s14vP9dF997eTJNWsdafadXhQ/uXKKTUlRR/OnKYBz/fRwmUxcnXNvxsyATOlpqaoX89wNbj7Hk2Z+r5K+vkp/uhRlbBbeXH8WLz69XpCD3Xppr7PRcrLq7gOHTwgdw8PJ1aO/Iygw3i5unuVvUqVKumTTz5Rq1at5O3trW3btqlatWr69NNP9fnnn+v77783q9Zc4+5V+U/Lpo01cMgwhd3fTve1aKI3335H97dtL0k6fOiQunbuqLmffaG76tZzbqG3Oe5elb9MfidK69eu0lffLr/uPeP3/7FPTz76sL5eslwVKla69QXChn+gOM+0dydpR9w2zZr92Q3nvDJ8iIoUKaIxb7x9CyvDP8nPd696fuFvTrv29K4hTru2mfL8nI6kpCRVqXI1yvf29rbdIrdZs2Zas2aNsdWhwMvKytLyH77T5cuXdFfdetr72x5duZKpe+9tYpsTXKWKAsoFaueOOOcVCuQzmZkZWv79Uj3Quet1G47Lly/puyWLFFi+gvwDApxQIZA/rFm9UrVCamvE0IFq37qZnny0qxZ/85XteHZ2tjasXa1KQZX14nN91b51Mz39xKNavfJnJ1aN/M5isTjtVVjluemoUqWKDh8+LEmqWbOmvvzyS0nS0qVL5evra2hxKLj2/7FPTe5poMYN79Ib40Zr4pSpqlq1ms6eOS03NzeH2FuSSpUqpbNnzjipWiD/Wf3LCl04f16dHnzYYfzrLz9X6yYN1bpJI8WuX6voGR/Kzc3dSVUCznfi+HEt/OoLVawUpHdnzFLX//TQpPFv6rsliyVJ55LO6tKlS/rk4w8V2qSZomd8oJb3hWn4kAHatmWzc4sHbiN5bjp69eqlHTt2SJJefvllTZs2TUWLFtWgQYM0bNgwQ4s7duyYnn766b+dk56ertTUVIdXenq6oXUg7yoHB+uLrxfpk3kL9J/uPTTq1Zd18OABZ5cFFBhLFy/UvU2bq0zZsg7j7Ts8oLmff6MZH36iipUq65Xhg/k7D7e17Oxs1agZoudfHKQaNUP08CPd1bnrI1r49YL/P351yXWLVvfpsScjdEfNWop4uq+atWhlmwPAfHluOgYNGqQXX3xRkhQWFqbff/9d8+fP1/bt2zVgwABDi0tKStLcuXP/dk5UVJR8fHwcXhPGRxlaB/LOzc1dlSoFKeTO2npx4BDdcUdNff7ZJypVuowyMzN1PjXVYf7Zs2e5exXw/06e+FObN8aqc5duOY4VL1FClYIqq37DRoqaMFlHDx9mmQhua6XLlFFw1aoOY5WDqyrx5ElJkm9JX7kWKXKdOVVsc4C/cnHiq7D6V8/pkKSgoCAFBQXd1HuXLFnyt8cPHTr0j+cYMWKEBg8e7DCWZWGpQX5jtWYrIyNDtULuVJEibtq4MVZh/39HniOHDynh5Ak2kQP/b9mSRSrp56cmzVv+7TyrVbLKqozMjL+dBxRmd9VtoKNHDjuMxR89YrsVrpubu0JCav/tHADmy1XTER0dnesTXktBcqNLly6yWCz6uxto/dOGGg8PD3n85ZZ33L3KuaKnTFTTZi1Urlw5Xbx4UT98v0xbNm/S9JkfqkSJEurStZsmvvO2fHx85OVVXG9Hva676taj6QB0danId98uUscHuqhIkf/9Ff3n8WP6+ccf1Di0qXxLltSpxER9MvtDeXh4qEmzFk6sGHCux554Sn16hmvOh++rTdv2+m33Li3+5iuNGDnaNueJnk/rlZcGq36DRmp49z36dcM6rVuzStM/nOO0upG/FeYN3c6Sq1vmBgcH5+5kFkuu0olrypcvr+nTp6tz587XPR4XF6eGDRvm+YGDNB3ONXrUK9q0MVZnTp9W8RIlVL16DfV6uo/ubdJU0v8eDrj8h++UkZmhJk2aacSro1S6dBknVw5umet8G2PXa8DzffXl4u9VKaiybfz0qVN6c+xI/b73N51PTZFfqdKq16Chevd7XkGVc/d3NMzDv0+ca92aVZoePVnH4o8qsHwFPfZEhLp0+4/DnCWLv9Hcjz7Q6VOJqhRUWX2f66+Wrds4qWJI+fuWuS8u/t1p147uUtNp1zZTnp/TYaSHHnpI9erV09ixY697fMeOHapfv76ys/P2DyGaDuDm0HQAN4emA8g7mo7rK6xNx7/e0/FvDBs2TBcvXrzh8WrVqumXX365hRUBAADgdufCLxIM59Smo3nz5n973MvLSy1b/v1GSgAAAAD5m1ObDgAAACC/IekwXmG+HTAAAACAfICkAwAAALDDLXONd1NJx9q1a/XEE08oNDRUf/75pyTp008/1bp16wwtDgAAAEDBl+em45tvvlG7du3k6emp7du3Kz09XZKUkpKiN9980/ACAQAAABRseW46Xn/9dc2cOVMffPCB3NzcbONNmzbVtm3bDC0OAAAAuNVcLM57FVZ5bjr27dunFi1a5Bj38fFRcnKyETUBAAAAKETy3HQEBATowIEDOcbXrVunKlWqGFIUAAAA4CwWi/NehVWem46+fftqwIAB2rhxoywWi06cOKF58+Zp6NCheu6558yoEQAAAEABludb5r788svKzs5WmzZtdOnSJbVo0UIeHh4aOnSoXnjhBTNqBAAAAFCAWaxWq/Vm3piRkaEDBw7owoULCgkJUfHixY2u7aZdyripjwTc9tKvZDu7BKBAKsxLIgCz+Hq6OruEG3r5+z+cdu23Ot7htGub6aYfDuju7q6QkBAjawEAAABQCOW56WjduvXfPqVx5cqV/6ogAAAAwJlu6unZ+Ft5bjrq1avn8HNmZqbi4uK0e/duRUREGFUXAAAAgEIiz03H5MmTrzs+evRoXbhw4V8XBAAAADgT+7SMZ1h69MQTT+jjjz826nQAAAAACgnDmo7Y2FgVLVrUqNMBAAAAKCTyvLyqa9euDj9brVadPHlSW7Zs0ciRIw0rDAAAAHAGF9ZXGS7PTYePj4/Dzy4uLqpRo4bGjh2rtm3bGlYYAAAAgMIhT01HVlaWevXqpTp16qhkyZJm1QQAAAA4DUGH8fK0p8PV1VVt27ZVcnKySeUAAAAAKGzyvJG8du3aOnTokBm1AAAAACiE8tx0vP766xo6dKiWLVumkydPKjU11eEFAAAAFGQuFue9Cqtc7+kYO3ashgwZoo4dO0qSHnroIVnsFrxZrVZZLBZlZWUZXyUAAACAAivXTceYMWP07LPP6pdffjGzHgAAAMCpuGWu8XLddFitVklSy5YtTSsGAAAAQOGTp1vmWuj6AAAAUMjxT17j5anpuOOOO/6x8UhKSvpXBQEAAAAoXPLUdIwZMybHE8kBAAAA4O/kqeno0aOHypYta1YtAAAAgNMV5lvXOkuun9PBfg4AAAAANyPPd68CAAAACjOL+GW70XKddGRnZ7O0CgAAAMhH/vzzTz3xxBMqVaqUPD09VadOHW3ZssV23Gq1atSoUSpXrpw8PT0VFham/fv3O5wjKSlJ4eHh8vb2lq+vr3r37q0LFy4YWmeumw4AAAAA+ce5c+fUtGlTubm56YcfftBvv/2miRMnqmTJkrY548ePV3R0tGbOnKmNGzfKy8tL7dq1U1pamm1OeHi49uzZo5iYGC1btkxr1qxRv379DK3VYi2E66YuZRS6jwTcEulXsp1dAlAgse0RyDtfT1dnl3BDb6086LRrv3xf1dzPffllrV+/XmvXrr3ucavVqsDAQA0ZMkRDhw6VJKWkpMjf319z5sxRjx49tHfvXoWEhGjz5s1q1KiRJGn58uXq2LGjjh8/rsDAwH//oUTSAQAAAOQb6enpSk1NdXilp6dfd+6SJUvUqFEj/ec//1HZsmVVv359ffDBB7bjhw8fVkJCgsLCwmxjPj4+aty4sWJjYyVJsbGx8vX1tTUckhQWFiYXFxdt3LjRsM9F0wEAAADYcbE47xUVFSUfHx+HV1RU1HXrPHTokGbMmKHq1avrxx9/1HPPPacXX3xRc+fOlSQlJCRIkvz9/R3e5+/vbzuWkJCQY992kSJF5OfnZ5tjhDw9pwMAAACAeUaMGKHBgwc7jHl4eFx3bnZ2tho1aqQ333xTklS/fn3t3r1bM2fOVEREhOm15gVJBwAAAGDHYrE47eXh4SFvb2+H142ajnLlyikkJMRhrFatWoqPj5ckBQQESJISExMd5iQmJtqOBQQE6NSpUw7Hr1y5oqSkJNscI9B0AAAAAAVQ06ZNtW/fPoexP/74Q0FBQZKk4OBgBQQEaMWKFbbjqamp2rhxo0JDQyVJoaGhSk5O1tatW21zVq5cqezsbDVu3NiwWlleBQAAABRAgwYNUpMmTfTmm2+qe/fu2rRpk2bNmqVZs2ZJuprYDBw4UK+//rqqV6+u4OBgjRw5UoGBgerSpYukq8lI+/bt1bdvX82cOVOZmZnq37+/evToYdidqySaDgAAAMCBSwG5Dfbdd9+tRYsWacSIERo7dqyCg4M1ZcoUhYeH2+a89NJLunjxovr166fk5GQ1a9ZMy5cvV9GiRW1z5s2bp/79+6tNmzZycXFRt27dFB0dbWitPKcDgA3P6QBuDs/pAPIuPz+nY+LqQ0679pCWVZx2bTORdAAAAAB2+EWC8dhIDgAAAMBUNB0AAAAATMXyKgAAAMCOC+urDEfSAQAAAMBUJB0AAACAnYJyy9yChKQDAAAAgKlIOgAAAAA7bOkwHkkHAAAAAFPRdAAAAAAwFcurAAAAADsuYn2V0Ug6AAAAAJiKpAMAAACww0Zy45F0AAAAADAVTQcAAAAAU7G8CgAAALDDE8mNR9IBAAAAwFQkHQAAAIAdF3aSG46kAwAAAICpaDoAAAAAmIrlVQAAAIAdVlcZj6QDAAAAgKlIOgAAAAA7bCQ3HkkHAAAAAFORdAAAAAB2CDqMR9IBAAAAwFQ0HQAAAABMxfIqAAAAwA6/lTce3ykAAAAAU5F0AAAAAHYs7CQ3HEkHAAAAAFPRdAAAAAAwFcurAAAAADssrjIeSQcAAAAAU5F0AAAAAHZc2EhuOJIOAAAAAKYi6QAAAADskHMYj6QDAAAAgKloOgAAAACYiuVVAAAAgB32kRuPpAMAAACAqUg6AAAAADsWog7DkXQAAAAAMBVNBwAAAABTsbwKAAAAsMNv5Y3HdwoAAADAVCQdAAAAgB02khuPpAMAAACAqUg6AAAAADvkHMYj6QAAAABgKpoOAAAAAKZieRUAAABgh43kxiuUTUdmltXZJQAFEn/HAjenXJMBzi4BKHAub5/q7BJwCxXKpgMAAAC4Wew/MB7fKQAAAABT0XQAAAAAMBXLqwAAAAA7bCQ3HkkHAAAAAFORdAAAAAB2yDmMR9IBAAAAwFQkHQAAAIAdtnQYj6QDAAAAgKloOgAAAACYiuVVAAAAgB0XtpIbjqQDAAAAgKlIOgAAAAA7bCQ3HkkHAAAAAFPRdAAAAAAwFcurAAAAADsWNpIbjqQDAAAAgKlIOgAAAAA7bCQ3HkkHAAAAAFORdAAAAAB2eDig8Ug6AAAAAJiKpgMAAACAqVheBQAAANhhI7nxSDoAAAAAmIqkAwAAALBD0mE8kg4AAAAApqLpAAAAAAq4t956SxaLRQMHDrSNpaWlKTIyUqVKlVLx4sXVrVs3JSYmOrwvPj5enTp1UrFixVS2bFkNGzZMV65cMbw+mg4AAADAjsWJ/3czNm/erPfff1933XWXw/igQYO0dOlSffXVV1q9erVOnDihrl272o5nZWWpU6dOysjI0IYNGzR37lzNmTNHo0aN+lff3/XQdAAAAAD5RHp6ulJTUx1e6enpN5x/4cIFhYeH64MPPlDJkiVt4ykpKfroo480adIk3XfffWrYsKFmz56tDRs26Ndff5Uk/fTTT/rtt9/02WefqV69eurQoYPGjRunadOmKSMjw9DPRdMBAAAA2HGxOO8VFRUlHx8fh1dUVNQNa42MjFSnTp0UFhbmML5161ZlZmY6jNesWVOVKlVSbGysJCk2NlZ16tSRv7+/bU67du2UmpqqPXv2GPqdcvcqAAAAIJ8YMWKEBg8e7DDm4eFx3blffPGFtm3bps2bN+c4lpCQIHd3d/n6+jqM+/v7KyEhwTbHvuG4dvzaMSPRdAAAAAB2bnZvhRE8PDxu2GTYO3bsmAYMGKCYmBgVLVr0FlT277C8CgAAAChgtm7dqlOnTqlBgwYqUqSIihQpotWrVys6OlpFihSRv7+/MjIylJyc7PC+xMREBQQESJICAgJy3M3q2s/X5hiFpgMAAAAoYNq0aaNdu3YpLi7O9mrUqJHCw8Nt/9nNzU0rVqywvWffvn2Kj49XaGioJCk0NFS7du3SqVOnbHNiYmLk7e2tkJAQQ+tleRUAAABgpyA8kbxEiRKqXbu2w5iXl5dKlSplG+/du7cGDx4sPz8/eXt764UXXlBoaKjuvfdeSVLbtm0VEhKiJ598UuPHj1dCQoJeffVVRUZG5mqJV17QdAAAAACF0OTJk+Xi4qJu3bopPT1d7dq10/Tp023HXV1dtWzZMj333HMKDQ2Vl5eXIiIiNHbsWMNrsVitVqvhZ3WylMvZzi4BKJCsKnR/HQC3RLkmA5xdAlDgXN4+1dkl3NCqfUlOu3arGn5Ou7aZ2NMBAAAAwFQ0HQAAAABMxZ4OAAAAwI5LAdhIXtCQdAAAAAAwFUkHAAAAYMeZTyQvrEg6AAAAAJiKpgMAAACAqVheBQAAANgpCE8kL2hIOgAAAACYiqQDAAAAsEPQYTySDgAAAACmIukAAAAA7LiwqcNwJB0AAAAATEXTAQAAAMBULK8CAAAA7LC4yngkHQAAAABMRdIBAAAA2CPqMBxJBwAAAABT0XQAAAAAMBXLqwAAAAA7FtZXGY6kAwAAAICpSDoAAAAAOzyQ3HgkHQAAAABMRdIBAAAA2CHoMB5JBwAAAABT0XQAAAAAMBXLqwAAAAB7rK8yHEkHAAAAAFORdAAAAAB2eDig8Ug6AAAAAJiKpgMAAACAqVheBQAAANjhieTGI+kAAAAAYCqSDgAAAMAOQYfxSDoAAAAAmIqkAwAAALBH1GE4kg4AAAAApqLpAAAAAGAqllcBAAAAdngiufFIOgAAAACYiqQDAAAAsMPDAY1H0gEAAADAVDQdAAAAAEzF8ioAAADADqurjEfSAQAAAMBUJB0AAACAPaIOw5F0AAAAADAVSQcAAABgh4cDGo+kAwAAAICpaDoAAAAAmIrlVQAAAIAdnkhuPJIOAAAAAKYi6QAAAADsEHQYj6QDAAAAgKloOgAAAACYiuVVAAAAgD3WVxmOpAMAAACAqUg6AAAAADs8kdx4JB0AAAAATEXSAQAAANjh4YDGo+mA4WbNmKoP35/mMBZUOVhfLf5eknT8WLzenTReO+K2KTMjQ/c2aa6hL7+iUqVKO6NcIN84lZioae9O1Ib1a5WelqYKFStp5Jg3VOvO2pKkS5cuatq7k7X6lxVKTUlWufLl9ehjT6jrf3o4uXLAPE0bVNWgp8LUIKSSypXxUfdBs7R01U7b8Vee6aj/tGugCgEllZGZpe174zV66lJt3n3UNqdapbJ6c1AXhdatInc3V+3ef0Jjpi/Tmi37JUl+Pl6a/UaE6txRXn4+xXQ66YKWrdqpUVOX6vzFtFv+mYHCiKYDpqhStZqmvv+x7ecirlf/X+3y5Ut64bk+qn5HDU2fNUeSNHNatIa8+Lw+/vQLubiw4g+3p9TUFPXrGa4Gd9+jKVPfV0k/P8UfPaoS3t62OVMmjNfWzb9qzBtvq1xgeW2MXa93osapdJmyatHqPidWD5jHy9NDu/74U598G6sFk/rlOH7g6CkNevsrHT5+Rp4ebnrhifu0dHp/1e48RmfOXZAkLYx+VgfiT6nDM9G6nJ6p/o+31sLoZ3Xng6OVePa8srOztWz1To2Zvkxnzp1XlYplNOXl7nrPx0s9/zvnFn9ioHCi6YApXF2LqHTpMjnGd2zfrpMn/tSnXyxU8eLFJUmjx0WpTYvG2rLpV91zb5NbXSqQL3w6+yOVDQjQqLFv2sYCy1dwmLNrx3Z1fLCLGt59jyTp4Ue6a9E3X+q33btoOlBo/bT+N/20/rcbHl+wfIvDz8MnLlSvh5uodvVArdr0h0r5eql6UFk9N2aedu8/IUkaGf2tnn20hUKqBSrx7D4ln7+sD75aZztH/MlzmvXVWg16KsycD4V8j9VVxuPXyjDFsfij6nh/C3XpdL9GjhimhJNX/6LPzMyQxWKRu7u7ba67h4dcXFwUt32bs8oFnG7N6pWqFVJbI4YOVPvWzfTko121+JuvHObUqVtfa1f9olOJibJardqyeaOOHT2ixqFNnVQ1kL+4FXFV765NlXz+knb98ack6WzyRe07nKDHH7hHxYq6y9XVRX26NVPi2VRt/y3+uucpV8ZHne+rp7Vb99/K8oFCzelJx+XLl7V161b5+fkpJCTE4VhaWpq+/PJLPfXUUzd8f3p6utLT0x3Hst3k4eFhSr34Z7Xr3KVRY99UUOVgnTlzWh/OnKZ+Tz+hz79eqtp16qqop6emTpmg518YJKusmvruJGVlZensmdPOLh1wmhPHj2vhV1/osSci1LNPP/22e7cmjX9Tbm5u6vRQF0nS0JdfUdTY1/Rgu9ZyLVJELhaL/jtqrOo3bOTc4gEn69C8tj55q5eKFXVTwplUPfDsVJ1Nvmg73unZqVowuZ9Or5+g7GyrTp+7oM6R05V8/rLDeeZG9dQDLe9SMU93LVu9S8+NnX+rPwryC6IOwzk16fjjjz9Uq1YttWjRQnXq1FHLli118uRJ2/GUlBT16tXrb88RFRUlHx8fh9ekd94yu3T8jSbNWiisbXtVv6OGQps005Sp7+v8+fP6+acfVNLPT1Hjp2jtmlVq2aSh7mt2jy6cT1XNWiGyuPAnHLev7Oxs1agZoudfHKQaNUP08CPd1bnrI1r49QLbnC8//0y7d+3QhHenae78rzRgyEt6J2qcNv26wYmVA863evMfatwjSq17TtJPG37TZ+OfVpmSxW3HJ4/ortNJ5xX29BQ1f/IdLfllh7559xkFlPZ2OM9LE75R6ONv65GB76tKhdJ6e0jXW/1RgELLqU3H8OHDVbt2bZ06dUr79u1TiRIl1LRpU8XHXz/uvJ4RI0YoJSXF4TV42MsmVo28KuHtrUqVKuv4sav/vd7bpKkWLftJP65cr59+2aAxb4zXqVOnVL58RSdXCjhP6TJlFFy1qsNY5eCqSvz/X8SkpaVpxntTNGDIcDVv2VrV76ih//QIV1i7Dpr3yRwnVAzkH5fSMnTo2Blt2nVEz42ZrytZ2Yp4+OoewVb33KGOzWvrqZdnK3bHIcX9flwDo77U5fRMPfFgY4fzJJ49rz+OJOq71bv0wuuf65nuLXI0JgBujlOXV23YsEE///yzSpcurdKlS2vp0qV6/vnn1bx5c/3yyy/y8vL6x3N4eHjkWEplvZxtVsm4CZcuXdSfx4+pdOmHHMZ9S5aUJG3e9KvOJZ1lIyxua3fVbaCjRw47jMUfPaKAcoGSpCtXrujKlSty+Usi6OLiouxs/s4D7LlYLPJwu/pPnGJFr+4h/Oufk+xsqyx/8zCGa+m7u5vTV6LDCXgiufGc+ifp8uXLKlLkfyVYLBbNmDFD/fv3V8uWLTV/PmspC6J3J41X8xatFFCuvM6cPqVZM96Ti6uL2rbvJElaunihKlepopIl/bRrZ5wmjn9Tjz0RoaDKwU6uHHCex554Sn16hmvOh++rTdv2+m33Li3+5iuNGDlaklS8eHE1aHi33ps8QR4eRVUuMFDbtmzWD8uWaMCQ4c4tHjCRl6e7qlb8390QK5cvpbvuKK9zqZd0Nvmihvdpp+9W71LCmRSV8i2uZ7q3UGBZXy2MuXpzko07D+tc6iV9OO4pvTnrB11Oy9TTXZuocvlSWr5ujySpXbMQlfXz1tY9R3XhUrpCqpbTm4O6aMP2g4o/meSUzw0UNhar1Wp11sXvuecevfDCC3ryySdzHOvfv7/mzZun1NRUZWVl5em8KSQdTvXK8MHavm2LUpKTVbKkn+rWb6Dn+g9UhYqVJElT352oZUsWKzUlReUCA9X1Pz30+BMRf/sbJ9waVjntrwNIWrdmlaZHT9ax+KMKLF9Bjz0RoS7d/mM7fvbMaU2LnqxNsRuUmpqigHKB6tLtP3qMPz9OV67JAGeXUGg1b1hdP32Y8/v9dMmveuGNLzT3zZ66u05llfL1UlLKJW3Zc1Rvf7BcW+3uTNUgpJJGRz6oBiGV5FbERXsPJejNWT/YbsXbolF1jen/oGpWCZCHWxEdT0zWtyvjNOHjGKVcuJzj2jDG5e1TnV3CDe1LuOS0a9cIKOa0a5vJqU1HVFSU1q5dq++///66x59//nnNnDkzz0sHaDqAm0PTAdwcmg4g72g6ro+mowCh6QBuDk0HcHNoOoC8y89Nxx9ObDruKKRNBw8HBAAAAGAqmg4AAAAApuI+cAAAAIA97s1hOJIOAAAAAKYi6QAAAADs8HBA45F0AAAAADAVTQcAAABQAEVFRenuu+9WiRIlVLZsWXXp0kX79u1zmJOWlqbIyEiVKlVKxYsXV7du3ZSYmOgwJz4+Xp06dVKxYsVUtmxZDRs2TFeuXDG0VpoOAAAAwI7F4rxXXqxevVqRkZH69ddfFRMTo8zMTLVt21YXL160zRk0aJCWLl2qr776SqtXr9aJEyfUtWtX2/GsrCx16tRJGRkZ2rBhg+bOnas5c+Zo1KhRRn2dkng4IAA7PBwQuDk8HBDIu/z8cMADpy477drVynre9HtPnz6tsmXLavXq1WrRooVSUlJUpkwZzZ8/X4888ogk6ffff1etWrUUGxure++9Vz/88IMeeOABnThxQv7+/pKkmTNnavjw4Tp9+rTc3d0N+VwkHQAAAIAdixNf6enpSk1NdXilp6fnqu6UlBRJkp+fnyRp69atyszMVFhYmG1OzZo1ValSJcXGxkqSYmNjVadOHVvDIUnt2rVTamqq9uzZk+vv7J/QdAAAAAD5RFRUlHx8fBxeUVFR//i+7OxsDRw4UE2bNlXt2rUlSQkJCXJ3d5evr6/DXH9/fyUkJNjm2Dcc145fO2YUbpkLAAAA5BMjRozQ4MGDHcY8PDz+8X2RkZHavXu31q1bZ1Zp/wpNBwAAAGDPiY/p8PDwyFWTYa9///5atmyZ1qxZowoVKtjGAwIClJGRoeTkZIe0IzExUQEBAbY5mzZtcjjftbtbXZtjBJZXAQAAAAWQ1WpV//79tWjRIq1cuVLBwcEOxxs2bCg3NzetWLHCNrZv3z7Fx8crNDRUkhQaGqpdu3bp1KlTtjkxMTHy9vZWSEiIYbWSdAAAAAB2CsoTySMjIzV//nx9++23KlGihG0Pho+Pjzw9PeXj46PevXtr8ODB8vPzk7e3t1544QWFhobq3nvvlSS1bdtWISEhevLJJzV+/HglJCTo1VdfVWRkZJ4Tl7/DLXMB2HDLXODmcMtcIO/y8y1zD51Oc9q1q5Qpmuu5lhs82GP27Nnq2bOnpKsPBxwyZIg+//xzpaenq127dpo+fbrD0qmjR4/queee06pVq+Tl5aWIiAi99dZbKlLEuHyCpgOADU0HcHNoOoC8y89Nx+Ezzms6gkvnvukoSNjTAQAAAMBUNB0AAAAATMVGcgAAAMBOwdhGXrCQdAAAAAAwFUkHAAAAYI+ow3AkHQAAAABMRdMBAAAAwFQsrwIAAADsFJQnkhckJB0AAAAATEXSAQAAANixEHQYjqQDAAAAgKlIOgAAAAA7BB3GI+kAAAAAYCqaDgAAAACmYnkVAAAAYIeN5MYj6QAAAABgKpIOAAAAwAFRh9FIOgAAAACYiqYDAAAAgKlYXgUAAADYYSO58Ug6AAAAAJiKpAMAAACwQ9BhPJIOAAAAAKYi6QAAAADssKfDeCQdAAAAAExF0wEAAADAVCyvAgAAAOxY2EpuOJIOAAAAAKYi6QAAAADsEXQYjqQDAAAAgKloOgAAAACYiuVVAAAAgB1WVxmPpAMAAACAqUg6AAAAADs8kdx4JB0AAAAATEXSAQAAANjh4YDGI+kAAAAAYCqaDgAAAACmYnkVAAAAYI/VVYYj6QAAAABgKpIOAAAAwA5Bh/FIOgAAAACYiqYDAAAAgKlYXgUAAADY4YnkxiPpAAAAAGAqkg4AAADADk8kNx5JBwAAAABTkXQAAAAAdtjTYTySDgAAAACmoukAAAAAYCqaDgAAAACmoukAAAAAYCo2kgMAAAB22EhuPJIOAAAAAKai6QAAAABgKpZXAQAAAHZ4IrnxSDoAAAAAmIqkAwAAALDDRnLjkXQAAAAAMBVJBwAAAGCHoMN4JB0AAAAATEXTAQAAAMBULK8CAAAA7LG+ynAkHQAAAABMRdIBAAAA2OHhgMYj6QAAAABgKpoOAAAAAKZieRUAAABghyeSG4+kAwAAAICpSDoAAAAAOwQdxiPpAAAAAGAqmg4AAAAApmJ5FQAAAGCP9VWGI+kAAAAAYCqSDgAAAMAOTyQ3HkkHAAAAAFORdAAAAAB2eDig8Ug6AAAAAJiKpgMAAACAqSxWq9Xq7CJw+0hPT1dUVJRGjBghDw8PZ5cDFAj8uQFuDn92gPyDpgO3VGpqqnx8fJSSkiJvb29nlwMUCPy5AW4Of3aA/IPlVQAAAABMRdMBAAAAwFQ0HQAAAABMRdOBW8rDw0OvvfYaG/qAPODPDXBz+LMD5B9sJAcAAABgKpIOAAAAAKai6QAAAABgKpoOAAAAAKai6QAAAABgKpoO3DLTpk1T5cqVVbRoUTVu3FibNm1ydklAvrZmzRo9+OCDCgwMlMVi0eLFi51dElAgREVF6e6771aJEiVUtmxZdenSRfv27XN2WcBtjaYDt8SCBQs0ePBgvfbaa9q2bZvq1q2rdu3a6dSpU84uDci3Ll68qLp162ratGnOLgUoUFavXq3IyEj9+uuviomJUWZmptq2bauLFy86uzTgtsUtc3FLNG7cWHfffbemTp0qScrOzlbFihX1wgsv6OWXX3ZydUD+Z7FYtGjRInXp0sXZpQAFzunTp1W2bFmtXr1aLVq0cHY5wG2JpAOmy8jI0NatWxUWFmYbc3FxUVhYmGJjY51YGQDgdpCSkiJJ8vPzc3IlwO2LpgOmO3PmjLKysuTv7+8w7u/vr4SEBCdVBQC4HWRnZ2vgwIFq2rSpateu7exygNtWEWcXAAAAYJbIyEjt3r1b69atc3YpwG2NpgOmK126tFxdXZWYmOgwnpiYqICAACdVBQAo7Pr3769ly5ZpzZo1qlChgrPLAW5rLK+C6dzd3dWwYUOtWLHCNpadna0VK1YoNDTUiZUBAAojq9Wq/v37a9GiRVq5cqWCg4OdXRJw2yPpwC0xePBgRUREqFGjRrrnnns0ZcoUXbx4Ub169XJ2aUC+deHCBR04cMD28+HDhxUXFyc/Pz9VqlTJiZUB+VtkZKTmz5+vb7/9ViVKlLDtH/Tx8ZGnp6eTqwNuT9wyF7fM1KlT9c477yghIUH16tVTdHS0Gjdu7OyygHxr1apVat26dY7xiIgIzZkz59YXBBQQFovluuOzZ89Wz549b20xACTRdAAAAAAwGXs6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AOAm9ezZU126dLH93KpVKw0cOPCW17Fq1SpZLBYlJyffcI7FYtHixYtzfc7Ro0erXr16/6quI0eOyGKxKC4u7l+dBwBQ8NF0AChUevbsKYvFIovFInd3d1WrVk1jx47VlStXTL/2woULNW7cuFzNzU2jAABAYVHE2QUAgNHat2+v2bNnKz09Xd9//70iIyPl5uamESNG5JibkZEhd3d3Q67r5+dnyHkAAChsSDoAFDoeHh4KCAhQUFCQnnvuOYWFhWnJkiWS/rck6o033lBgYKBq1KghSTp27Ji6d+8uX19f+fn5qXPnzjpy5IjtnFlZWRo8eLB8fX1VqlQpvfTSS7JarQ7X/evyqvT0dA0fPlwVK1aUh4eHqlWrpo8++khHjhxR69atJUklS5aUxWJRz549JUnZ2dmKiopScHCwPD09VbduXX399dcO1/n+++91xx13yNPTU61bt3aoM7eGDx+uO+64Q8WKFVOVKlU0cuRIZWZm5pj3/vvvq2LFiipWrJi6d++ulJQUh+MffvihatWqpaJFi6pmzZqaPn36Da957tw5hYeHq0yZMvL09FT16tU1e/bsPNcOACh4SDoAFHqenp46e/as7ecVK1bI29tbMTExkqTMzEy1a9dOoaGhWrt2rYoUKaLXX39d7du3186dO+Xu7q6JEydqzpw5+vjjj1WrVi1NnDhRixYt0n333XfD6z711FOKjY1VdHS06tatq8OHD+vMmTOqWLGivvnmG3Xr1k379u2Tt7e3PD09JUlRUVH67LPPNHPmTFWvXl1r1qzRE088oTJlyqhly5Y6duyYunbtqsjISPXr109btmzRkCFD8vydlChRQnPmzFFgYKB27dqlvn37qkSJEnrppZdscw4cOKAvv/xSS5cuVWpqqnr37q3nn39e8+bNkyTNmzdPo0aN0tSpU1W/fn1t375dffv2lZeXlyIiInJcc+TIkfrtt9/0ww8/qHTp0jpw4IAuX76c59oBAAWQFQAKkYiICGvnzp2tVqvVmp2dbY2JibF6eHhYhw4dajvu7+9vTU9Pt73n008/tdaoUcOanZ1tG0tPT7d6enpaf/zxR6vVarWWK1fOOn78eNvxzMxMa4UKFWzXslqt1pYtW1oHDBhgtVqt1n379lklWWNiYq5b5y+//GKVZD137pxtLC0tzVqsWDHrhg0bHOb27t3b+thjj1mtVqt1xIgR1pCQEIfjw4cPz3Guv5JkXbRo0Q2Pv/POO9aGDRvafn7ttdesrq6u1uPHj9vGfvjhB6uLi4v15MmTVqvVaq1atap1/vz5DucZN26cNTQ01Gq1Wq2HDx+2SrJu377darVarQ8++KC1V69eN6wBAFB4kXQAKHSWLVum4sWLKzMzU9nZ2Xr88cc1evRo2/E6deo47OPYsWOHDhw4oBIlSjicJy0tTQcPHlRKSopOnjypxo0b244VKVJEjRo1yrHE6pq4uDi5urqqZcuWua77wIEDunTpku6//36H8YyMDNWvX1+StHfvXoc6JCk0NDTX17hmwYIFio6O1sGDB3XhwgVduXJF3t7eDnMqVaqk8uXLO1wnOztb+/btU4kSJXTw4EH17t1bffv2tc25cuWKfHx8rnvN5557Tt26ddO2bdvUtm1bdenSRU2aNMlz7QCAgoemA0Ch07p1a82YMUPu7u4KDAxUkSKOf9V5eXk5/HzhwgU1bNjQtmzIXpkyZW6qhmvLpfLiwoULkqTvvvvO4R/70tV9KkaJjY1VeHi4xowZo3bt2snHx0dffPGFJk6cmOdaP/jggxxNkKur63Xf06FDBx09elTff/+9YmJi1KZNG0VGRmrChAk3/2EAAAUCTQeAQsfLy0vVqlXL9fwGDRpowYIFKlu2bI7f9l9Trlw5bdy4US1atJB09Tf6W7duVYMGDa47v06dOsrOztbq1asVFhaW4/i1pCUrK8s2FhISIg8PD8XHx98wIalVq5ZtU/w1v/766z9/SDsbNmxQUFCQXnnlFdvY0aNHc8yLj4/XiRMnFBgYaLuOi4uLatSoIX9/fwUGBurQoUMKDw/P9bXLlCmjiIgIRUREqHnz5ho2bBhNBwDcBrh7FYDbXnh4uEqXLq3OnTtr7dq1Onz4sFatWqUXX3xRx48flyQNGDBAb731lhYvXqzff/9dzz///N8+Y6Ny5cqKiIjQ008/rcWLF9vO+eWXX0qSgoKCZLFYtGzZMp0+fVoXLlxQiRIlNHToUA0aNEhz587VwYMHtW3bNr333nuaO3euJOnZZ5/V/v37NWzYMO3bt0/z58/XnDlz8vR5q1evrvj4eH3xxRc6ePCgoqOjtWjRohzzihYtqoiICO3YsUNr167Viy++qO7duysgIECSNGbMGEVFRSk6Olp//PGHdu3apdmzZ2vSpEnXve6oUaP07bff6sCBA9qzZ4+WLVumWrVq5al2AEDBRNMB4LZXrFgxrVmzRpUqVVLXrl1Vq1Yt9e7dW2lpabbkY8iQIXryyScVERGh0NBQlShRQg8//PDfnnfGjBl65JFH9Pzzz6tmzZrq27evLl68KEkqX768xowZo5dffln+/v7q37+/JGncuHEaOXKkoqKiVKtWLbVv317fffedgoODJV3dZ/HNN99o8eLFqlu3rmbOnKk333wzT5/3oYce0qBBg9S/f3/Vq1dPGzZs0MiRI3PMq1atmrp27aqOHTuqbdu2uuuuuxxuidunTx99+OGHmj17turUqaOWLVtqzpw5tlr/yt3dXSNGjNBdd92lFi1ayNXVVV988UWeagcAFEwW6412QQIAAACAAUg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJiKpgMAAACAqWg6AAAAAJjq/wCn29zlbrlDKgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('/content/drive/MyDrive/mo.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "UU-loQp2KIUK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "OiUcQ7GsgaXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \" كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفطار. ومع ذلك فقد كانت وجبة العشاء في المطعم باهظة الثمن وغير مرضية\"\n",
        "target='الغرفة'\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  target,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=True,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n",
        "encoding = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  add_special_tokens=True,\n",
        "  max_length=128,\n",
        "  return_token_type_ids=False,\n",
        "  padding=\"max_length\",\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n",
        "#_, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "#test_prediction = test_prediction.flatten().numpy()\n",
        "\n",
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "token_type_ids = encoded_review['token_type_ids'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask, token_type_ids)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'target text: {target}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')\n",
        "print(f'Labels  : ')\n",
        "#for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
        "#  if prediction < THRESHOLD:\n",
        "#    continue\n",
        " # print(f\"{label}: {prediction}\")"
      ],
      "metadata": {
        "id": "om8Fo_STgZ_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704d0716-8eaa-47bd-c7b7-81c1923a9a6a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text:  كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفطار. ومع ذلك فقد كانت وجبة العشاء في المطعم باهظة الثمن وغير مرضية\n",
            "target text: الغرفة\n",
            "Sentiment  : positive\n",
            "Labels  : \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-Iy0MzdU0wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SentimentClassifier(len(class_names))\n",
        "model2.load_state_dict(torch.load('/content/best_model_state_ARABERT.bin',  map_location=torch.device('cpu')))\n",
        "model2.eval()\n",
        "model2.to(device)"
      ],
      "metadata": {
        "id": "nM1BC3Q5P-Gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44c4dbb-f2ae-4101-907d-0be1d8fbf1b4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"الفندق جيد والسعر معقول  \"\n",
        "target='السعر'\n",
        "#['لموظفون','SERVICE#GENERAL']\n",
        "# target='الموظفون'\n",
        "#category='SERVICE#GENERAL'\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  target,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=True,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n",
        "\n",
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "token_type_ids = encoded_review['token_type_ids'].to(device)\n",
        "\n",
        "output = model2(input_ids, attention_mask, token_type_ids)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'target text: {target}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "metadata": {
        "id": "K2D0r7ePU1gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e08cb8-95b1-432c-f882-101656426187"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text: الفندق جيد والسعر معقول  \n",
            "target text: السعر\n",
            "Sentiment  : positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOXcLsuYU9Vv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}